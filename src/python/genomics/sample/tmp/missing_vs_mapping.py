import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import sys
import os
import argparse
from sklearn.linear_model import HuberRegressor, LinearRegression

def plot_dual_regression(df, x_col, y_col, x_label, y_label, filename):
    print(f"Running regressions for {y_label} vs {x_label}...")
    
    # Filter valid data
    local_valid = df[[x_col, y_col]].replace([np.inf, -np.inf], np.nan).dropna()
    
    if len(local_valid) < 10:
        print(f"Not enough valid data for {filename}")
        return

    X = local_valid[x_col].values.reshape(-1, 1)
    y = local_valid[y_col].values
    
    # 1. OLS Regression
    ols = LinearRegression()
    ols.fit(X, y)
    ols_slope = ols.coef_[0]
    ols_intercept = ols.intercept_
    ols_score = ols.score(X, y)
    ols_eq = f"y = {ols_slope:.4f}x + {ols_intercept:.4f}"
    
    # 2. Huber Regression (Robust to outliers)
    huber = HuberRegressor(epsilon=1.35)
    huber.fit(X, y)
    huber_slope = huber.coef_[0]
    huber_intercept = huber.intercept_
    huber_score = huber.score(X, y) 
    huber_eq = f"y = {huber_slope:.4f}x + {huber_intercept:.4f}"
    
    # Plotting: JointGrid
    # Need 'Group' for hue
    local_valid_plot = df[[x_col, y_col, 'Group']].replace([np.inf, -np.inf], np.nan).dropna()

    # Create JointGrid
    g = sns.JointGrid(data=local_valid_plot, x=x_col, y=y_col, height=10, ratio=5)

    # 1. Main Scatter Plot
    # Enable legend='full' to ensure all groups are generated
    sns.scatterplot(data=local_valid_plot, x=x_col, y=y_col, hue='Group',
                    alpha=0.6, s=20, edgecolor='none', ax=g.ax_joint, legend='full')
    
    # 2. Add Regression Lines to Main Plot
    x_min, x_max = local_valid[x_col].min(), local_valid[x_col].max()
    x_span = x_max - x_min
    if x_span == 0: x_span = 0.01
    
    # Extend range slightly for lines
    x_range = np.linspace(x_min - 0.05*x_span, x_max + 0.05*x_span, 100).reshape(-1, 1)
    
    y_ols = ols.predict(x_range)
    y_huber = huber.predict(x_range)
    
    line1, = g.ax_joint.plot(x_range, y_ols, color='blue', linewidth=2, linestyle='--', 
                    label=f'OLS: {ols_eq}\n$R^2$={ols_score:.3f}')
    line2, = g.ax_joint.plot(x_range, y_huber, color='red', linewidth=2, 
                    label=f'Huber: {huber_eq}\n$R^2$={huber_score:.3f}')
    
    # --- Legend Management ---
    # 1. Retrieve the Group Legend created by sns.scatterplot
    group_legend = g.ax_joint.get_legend()
    if group_legend:
        group_legend.set_bbox_to_anchor((1.25, 1.0))
        group_legend.set_loc('upper left')
        group_legend.set_title("Sample Groups")
        group_legend.set_frame_on(False)
    
    # 2. Create Regression Legend
    # This creates a new legend and removes the old one from the axes "legend" slot
    reg_legend = g.ax_joint.legend(handles=[line1, line2], 
                                   title="Regression Models", 
                                   loc='upper left', 
                                   bbox_to_anchor=(1.25, 0.4), # Positioned below Group legend
                                   frameon=False)
    
    # 3. Add Group Legend back as an artist (so both are visible)
    if group_legend:
        g.ax_joint.add_artist(group_legend)
    
    # 3. Marginals (Stacked Histograms)
    sns.histplot(data=local_valid_plot, x=x_col, hue='Group', multiple='stack', 
                 bins=2000, linewidth=0.1, ax=g.ax_marg_x, legend=False)
    sns.histplot(data=local_valid_plot, y=y_col, hue='Group', multiple='stack', 
                 bins=50, linewidth=0.1, ax=g.ax_marg_y, legend=False)

    g.ax_joint.set_xlabel(x_label)
    g.ax_joint.set_ylabel(y_label)
    # g.ax_joint.set_xlim(x_min - 0.05*x_span, x_max + 0.05*x_span)
    g.ax_joint.set_xlim(99, 100.1)
    
    plt.suptitle(f'{y_label} vs {x_label}', y=1.02, fontsize=16)
    
    plt.savefig(filename, dpi=300, bbox_inches='tight')
    print(f"Saved plot to {filename}")
    plt.close()

def missing_vs_mapping(
    mapping_file="/data1/dazheng_tusr1/vmap4.VCF.v1/vmap4_v1_idxstat_summary.txt", 
    smiss_file="/data1/dazheng_tusr1/vmap4.VCF.v1/chr002.missing.smiss", 
    group_file="/data1/dazheng_tusr1/vmap4.VCF.v1/sample_group.txt", 
    output_prefix="missing_vs_mapping_zoomed"
):
    print("Processing Missing Rate vs Mapping Rate Analysis...")
    
    # 1. Read Mapping Rate Data
    print(f"Reading Mapping Rate file: {mapping_file}...")
    try:
        df_map = pd.read_csv(mapping_file, sep='\t')
    except Exception as e:
        print(f"Error reading mapping file: {e}")
        return
        
    # Check Columns (generated by sample_mapping_rate_idxstats.py)
    # Expected: "TaxaID", "BamPath", "Mapped_Reads", "Unmapped_Reads", "Mapping_Rate_Pct"
    if 'TaxaID' not in df_map.columns or 'Mapping_Rate_Pct' not in df_map.columns:
        print(f"Error: Required columns ('TaxaID', 'Mapping_Rate_Pct') not found in mapping file.")
        print(f"Columns found: {list(df_map.columns)}")
        return
        
    df_map = df_map[['TaxaID', 'Mapping_Rate_Pct']].rename(columns={'TaxaID': 'Sample'})
    
    # 2. Read .smiss Data
    print(f"Reading .smiss file: {smiss_file}...")
    try:
        df_missing = pd.read_csv(smiss_file, sep=r'\s+')
    except Exception as e:
        print(f"Error reading smiss file: {e}")
        return
        
    # Handle IID
    iid_col = None
    for col in ['#IID', 'IID', 'INDV']:
        if col in df_missing.columns:
            iid_col = col
            break
            
    if not iid_col:
        print(f"Error: Could not find Sample ID column in {smiss_file}. Found: {list(df_missing.columns)}")
        return
        
    missing_col = 'F_MISS'
    if missing_col not in df_missing.columns:
        print(f"Error: Missing '{missing_col}' in smiss file.")
        return
        
    df_missing = df_missing[[iid_col, missing_col]].rename(columns={iid_col: 'Sample', missing_col: 'Missing_Rate'})
    
    # 3. Merge Datasets
    print("Merging datasets...")
    df_merged = pd.merge(df_map, df_missing, on='Sample', how='inner')
    print(f"Matched samples: {len(df_merged)}")
    
    if len(df_merged) == 0:
        print("Error: No intersecting samples found between mapping file and smiss file.")
        return
        
    # 4. Integrate Group Info
    print(f"Reading Group info: {group_file}...")
    if os.path.exists(group_file):
        try:
            df_group = pd.read_csv(group_file, sep=r'\s+', header=None, names=['Sample', 'Group'])
            df_group = df_group.drop_duplicates(subset=['Sample'])
            df_merged = pd.merge(df_merged, df_group, on='Sample', how='left')
            df_merged['Group'] = df_merged['Group'].fillna('Unknown')
        except Exception as e:
            print(f"Warning: Failed to process group file: {e}")
            df_merged['Group'] = 'Unknown'
    else:
        print(f"Warning: Group file not found at {group_file}")
        df_merged['Group'] = 'Unknown'
        
    # Print basic stats
    print(f"Correlation (Pearson): {df_merged['Mapping_Rate_Pct'].corr(df_merged['Missing_Rate']):.4f}")
    
    # Set style
    sns.set_theme(style="ticks")
    
    # 5. Plot
    output_filename = f"{output_prefix}_reg_miss_vs_map.png"
    plot_dual_regression(df_merged, 'Mapping_Rate_Pct', 'Missing_Rate',
                         'Mapping Rate (%)', 'Missing Rate (F_MISS)',
                         output_filename)
                         
    print("Analysis Complete.")

if __name__ == "__main__":
    missing_vs_mapping()